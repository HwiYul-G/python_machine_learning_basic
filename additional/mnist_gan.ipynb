{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숫자 생성 인공지능 개발 원리\n",
    "\n",
    "# GAN(Generative adversarial network, 갠 or 간) - 적대 생성 신경망\n",
    "# 생성자와 판별자는 서로를 이기기 위해 학습하기 시작한다. \n",
    "# 그러면 생성자는 판별자가 진짜/가짜를 구별 못하도록 진짜같은 것을 만든다\n",
    "# 두 개의 신경망을 이용해 새로운 그림을 생성하는 기법이 적대적 생성 신경망, GAN이다.\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers.activation import LeakyReLU # 강좌 기준으론 from keras.layers.advacned_activations import LeakyReLU 였다.\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# 모델 학습을 시각적으로 보여주는 라이브러리. \n",
    "# tqdm은 진행을 나타네는 아랍어(taqadum)에서 딴 이름\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n",
      "(10000, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# mnist 데이터셋의 그림은 0-255까지의 숫자로 이루어짐. 그 중간값인 127.5를 빼고 다시 그것으로 나누면\n",
    "# 0은 -1로, 255는 1로 바뀌며 그 중간 값 또한 비율에 따라 축소됨\n",
    "x_test = (x_test.astype(np.float32) - 127.5)/127.5 \n",
    "\n",
    "# 28x28 형태인 데이터를 1열로 나타내기위해 데이터의 형태를 바꿈\n",
    "mnist_data = x_test.reshape(10000, 784)\n",
    "print(mnist_data.shape)\n",
    "len(mnist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 256)               25856     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 784)               402192    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 559,632\n",
      "Trainable params: 559,632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 생성자 신경망 만들기\n",
    "# 생성자 신경망에 아무런 의미가 없는 숫자(노이즈값)을 입력하면 그럴듯한 숫자 이미지를 만들어낸다.\n",
    "# 하지만 지금 만든느 생성자 신경망은 아직 학습되지 않아서 적대적 생성 신경망(GAN)을 통해 판별자를 속일 수 있도록 학습시킬 예정\n",
    "\n",
    "from email import utils\n",
    "\n",
    "\n",
    "def create_generator():\n",
    "    generator = Sequential()\n",
    "    # 입력하는 값은 100으로 하고(의미있는 숫자는 아님), 이 백개의 픽세은 노이즈 값으로 100개의 픽셁밧이 랜덤하게 생성된다.\n",
    "    # 생성자는 무에서 유를 창조하지 않으므로 이런 노이즈값을 줘야한다.\n",
    "    # 생성자에게 아무것도 아닌 어떤 데이터를 주면 그것을 특정한 숫자의 모습으로 탈바꿈시킴\n",
    "    # 이 신경망의 첫 번째 층은 256개의 노드로 구성됨\n",
    "    generator.add(Dense(units= 256, input_dim = 100))\n",
    "    \n",
    "    # 1번 층의 활성화 함수는 LeakeyReLU 사용 기울기 0.2로\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    # 2번 층\n",
    "    generator.add(Dense(units=512))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    # 마지막 층(출력층)의 호라성화 함수는 tanh를 사용하고\n",
    "    # 784개로 노드가 있는데 mnist 데이터 못브이 28x28 픽셀로 이루어져 잇기 때문이다.\n",
    "    generator.add(Dense(units=784, activation='tanh'))\n",
    "    return generator\n",
    "\n",
    "g = create_generator()\n",
    "g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 512)               401920    \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 256)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 533,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Y\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 판별자 신경망 만들기\n",
    "\n",
    "def create_discriminator():\n",
    "    discriminator = Sequential()\n",
    "    discriminator.add(Dense(units=512, input_dim = 784))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dense(units=256))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    # 진짜인지 가짜인지 두 개중 하나로 구분하는 신경망이므로 오차값은 이항교차 엔트로피(binary_crossentropy)시영\n",
    "    # GAM을 만들려면 이전보단 더 정교하게 옵티마이저를 사용해야한다. 따라서 Adam 학습속도는 0.0002로 베타 최적화 값을 0.5로 설정\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr = 0.0002, beta_1=0.5))\n",
    "    \n",
    "    return discriminator\n",
    "\n",
    "d = create_discriminator()\n",
    "d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 784)               559632    \n",
      "                                                                 \n",
      " sequential_3 (Sequential)   (None, 1)                 533505    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,093,137\n",
      "Trainable params: 559,632\n",
      "Non-trainable params: 533,505\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GAN  생성 함수 만들기\n",
    "\n",
    "# 생성자 신경망과 판별자 신경망을 적절히 학습시키기\n",
    "def create_gan(discriminator, generator):\n",
    "    # 판별자가 학습을 못하도록 막아줌\n",
    "    discriminator.trainable = False\n",
    "    \n",
    "    # 적대적 생성 신경망인 gan에 입력할 데이터의 모습을 정하는 코드, 입력할 데이터 형태를 만들어 줌\n",
    "    # 입력하는 값은 100개의 값으로 이루어진 데이터임\n",
    "    gan_input = Input(shape=(100, ))\n",
    "    \n",
    "    # 생성자 신경망에게 바로 윗줄에서 작성한 픽셀 100개의 값과 데이터의 전체수(Input(shape=(100,)))만큼 데이터를 넣는다.\n",
    "    # 이 픽셀 100개는 노이즈 값, 이렇게 데이터를 넣으면 생성자가 만든 새로운 그림들이 변수 x에 저장된다.\n",
    "    x = generator(gan_input)\n",
    "    \n",
    "    # 적대적 생성 신경망 gan의 결괏값 데이터를 정의해주는 코드로\n",
    "    # 이 결괏값 데이터는 바로 판별자가 생상자가 만든 그림(x)를 보고 판단한 결과이다.\n",
    "    gan_output = discriminator(x)\n",
    "    \n",
    "    # 적대적 신경망 gan 모델 만들기\n",
    "    # input은 생성자 신경망이 만든 그림(노이즈값), 출력값은 판별자 신경망이 판단한 결과이다.\n",
    "    gan = Model(inputs = gan_input, outputs = gan_output)\n",
    "    \n",
    "    # 신경망의 오차를 줄이기 위한 방법\n",
    "    # 출력ㄱ밧이 OX를 판단하는 것이므로 이진\n",
    "    gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return gan\n",
    "\n",
    "gan = create_gan(d, g)\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 확인 함수 만들기\n",
    "\n",
    "def plot_generated_images(generator):\n",
    "    # 생성자에 넣어줄 노이즈값을 만들고 넘파이 랜덤값 생성 라이브러리중 정규 분포 함수 사용\n",
    "    # scale = 1은 -1에서 1 사이의 값을 생성한다는 뜻\n",
    "    # arg3 : 노이즈 100개를 생성하며, 각 노이즈는 숫자 100개씩으로 구성되어 있다는 뜻\n",
    "    # 함수 호출마다 100개의 그림을 그려달라고 요청\n",
    "    noise = np.random.normal(loc=0, scale =1, size=[100,100])\n",
    "    \n",
    "    # generator도 신경망 모델이므로 predictㄱ ㅏ능\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = generated_images.reshape(100,  28, 28)\n",
    "    plt.figure(figsize=(10, 10)) # 그림의 크기를 10x10으로 정해줌\n",
    "    \n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(10, 10, i+1)\n",
    "        plt.imshow(generated_images[i], interpolation='nearest')\n",
    "        plt.axis('off') # 그림 이름을 넣지 않는다.\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 적대적 생성 신경망 훈련시키기\n",
    "\n",
    "batch_size = 128 # 한 번에 몇 개의 그림을 학습시킬지\n",
    "epochs = 5000 # 몇 번 반복해서 학습시킬지\n",
    "\n",
    "# 신경망을 학습시킬 차례로 반복문과 tqdm 라이브러리를 사용해 반복 학습을 진행\n",
    "for e in tqdm(range(epochs)):\n",
    "    \n",
    "    # 생성자에게 줄 노이즈값을 만듦\n",
    "    # 이때 균일한 값을 생성할 수 잇도록 넘파이의 랜덤값 생성 라이브러리 중 정규 분포 함수 사용\n",
    "    # 평균을 0으로 -1, 1까지 128개(batch_size)만큼 만드는대 각각 100개씩\n",
    "    noise = np.random.normal(0,1,[batch_size, 100])\n",
    "    # 생성자 모델에 노이즈를 입력해, 생성자 신경망이 그림을 그린 뒤(예측한 뒤) 그림 결과를 generated_images에 저장\n",
    "    generated_images = g.predict(noise)\n",
    "    \n",
    "    # 학습할 때마다 다양한 손글씨를 인공지능이 학습하도록\n",
    "    # 실제 mnist 데이터셋 10000개에서 128개만 랜덤으로 뽑는 코드\n",
    "    image_batch = mnist_data[np.random.randint(low = 0, hight = mnist_data.shape[0], size = batch_size)]\n",
    "    \n",
    "    # 실제 mnist데이터인 image_batch와 가짜 그림 generated_images를 합침(한줄로 세움)\n",
    "    X = np.concatenate([image_batch, generated_images])\n",
    "    \n",
    "    y_dis = np.zeros(2*batch_size) \n",
    "    y_dis[:batch_size] = 1 # 앞의 128개는 진짜이므로 1이라고 true를 표기함\n",
    "    \n",
    "    # 정답을 보고 학습해 생성자가 만든 그림과 진짜 그림을 구분할 수 있어야 하기 때문에\n",
    "    # 처음에는 판별자가 먼저 학습할 수 있도록 해야한다.\n",
    "    d.trainable = True\n",
    "    d.train_on_batch(X, y_dis) # 판별자를 학습시킴 -> 오차를 줄이는 방식으로 학습해감\n",
    "    \n",
    "    # 새로운 노이즈값 생성\n",
    "    noise = np.random.normal(0,1, [batch_size, 100])\n",
    "    \n",
    "    # gan에 넣어줄 값을 만들고 모두 1로 설정\n",
    "    y_gen = np.ones(batch_size)\n",
    "    d.trainable = False # 판별자가 학습 못하게 설정(생성자가 만든 그림이 진짜인지 가짜인지 판별하는 역할만함)\n",
    "    \n",
    "    # gan에서 노이즈값을 입력으로하고 y_gen을 출력으로 넣음\n",
    "    # 출력값은 입력된 그림이 진짜인지 가짜인지 알려주는 판별자 신경망을 거쳐서 나오는 값(판별 결과)이다.\n",
    "    gan.train_on_batch(noise, y_gen)\n",
    "    \n",
    "    # 각 에포크별로 훈련을 잘하는 지 살펴보기\n",
    "    # 첫 번째 에포크 e == 1과 1000, 2000 ... 5000번째 에포크일때 생성자가 만든 그림 출력\n",
    "    if e == 1 or e%1000 == 0:\n",
    "        plot_generated_images(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a7a68ff6df131d9ae7a0f60e2ded381d5113c51d2c465edd8572fa159edd1df8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
